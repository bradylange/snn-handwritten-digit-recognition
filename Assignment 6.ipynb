{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CSIS 452 - Applied Machine Learning</center>\n",
    "## Assignment 6 - due: 4/30/2020\n",
    "In this assignment you will develop a Shallow Neural Network (SNN) for handwritten digit recognition using MNIST data set.\n",
    "\n",
    "Enter your name as a comment in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to display a random sample of images along with targets and predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_a_random_sample_of_images(grid_size, images, targets, predictions=np.array([]), title=\"images\"):\n",
    "    \"\"\" \n",
    "    Displayes a random sample of images with the corresponding targets\n",
    "    \n",
    "    \n",
    "    Argument:\n",
    "        grid_size -- size of subplot will be grid_sizeXgrid_size.\n",
    "        images -- an array of images 32x32  (num_images x 8 x 8)\n",
    "        targets -- an array of class values (num_images x 1) containing class values \n",
    "             between 0 and 9  \n",
    "        predictions -- an array of predicted class values (nume_images X 1) containig predicted\n",
    "             class values between 0 and 9\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    class_names = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    #reshape the images for display\n",
    "    \n",
    "    fig, axes1 = plt.subplots(grid_size,grid_size,figsize=(3,3))\n",
    "    fig.suptitle(title, fontsize=\"x-small\")\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.8, hspace=0.8)\n",
    "    \n",
    "    for j in range(grid_size):\n",
    "        for k in range(grid_size):\n",
    "            i = np.random.choice(range(len(images)))\n",
    "            axes1[j][k].set_axis_off()\n",
    "            if predictions.size > 0:\n",
    "                axes1[j][k].set_title(class_names[targets[i]]+\",\"+class_names[predictions[i]])\n",
    "            else:\n",
    "                axes1[j][k].set_title(class_names[targets[i]])\n",
    "            axes1[j][k].title.set_fontsize(8)\n",
    "            axes1[j][k].imshow(images[i, :,:], cmap = matplotlib.cm.binary, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the data set from keras datasets.  You will need to look at Keras datasets documentation, learn about the MNIST data set and develop the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy your code from last assignment and place it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the images and display a random sample of 9 images in a 3-by-3 grid along with their corresponding target class using the functions developed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_digits()\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "np.random.seed(2)\n",
    "display_a_random_sample_of_images(3, X_train, y_train, title=\"images\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output:\n",
    "<img src=\"Figure1.png\" width=\"20%\" height=\"20%\" align=\"left\"> <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will reshape the train images from 60000 x 28 x 28 to 60000 x 784 and test images from 10000 x 28 x 28 to 10000 x 784. This way, each image will be represented with a vector of 784 pixel values. We will also reshape the targets to a rank-2 vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy your code from last assignment and place it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output:\n",
    "(60000, 784) (60000, 1) (10000, 784) (10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now develop and train a three-layer (nx-128(tanh)-64(tanh)-ny(softmax)) Shallow Neural Network and train it using the data we just extracted.\n",
    "\n",
    "Let's OneHot encode the targets first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = #REPLACE WITH YOUR CODE\n",
    "y_train_1hot = #REPLACE WITH YOUR CODE\n",
    "y_test_1hot = #REPLACE WITH YOUR CODE\n",
    "print(y_train_1hot.shape)\n",
    "print(y_test_1hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output:\n",
    "(60000, 10)\n",
    "(10000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the model and train the it.  Use validation_split of 0.1 to allow for a 10% validation set.  Keep in mind that this is a multi-class problem, so your loss should be <b>categorical_crossentropy</b> and for metrics use <b>accuracy</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = #REPLACE WITH YOUR CODE\n",
    "n_hidden1 = #REPLACE WITH YOUR CODE\n",
    "n_hidden2 = #REPLACE WITH YOUR CODE\n",
    "n_outputs = num_classes  \n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "    \n",
    "model = #REPLACE WITH YOUR CODE\n",
    "\n",
    "model.add(#REPLACE WITH YOUR CODE)\n",
    "model.add(#REPLACE WITH YOUR CODE)\n",
    "model.add(#REPLACE WITH YOUR CODE)\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=learning_rate)\n",
    "model.compile(#REPLACE WITH YOUR CODE)\n",
    "\n",
    "history = model.fit(verbose=1, #REPLACE WITH YOUR CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot training curves and see how the model is doing on training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fig = plt.figure()\n",
    "training_ax = training_fig.add_subplot(111)\n",
    "training_ax.plot(history.history['loss'])\n",
    "training_ax.plot(history.history['acc'])\n",
    "training_ax.set_title('Training loss and accuracy')\n",
    "training_ax.set_xlabel('epoch')\n",
    "training_ax.legend(['loss', 'accuracy'], loc='upper right')\n",
    "\n",
    "validation_fig = plt.figure()\n",
    "validation_ax = validation_fig.add_subplot(111)\n",
    "validation_ax.plot(history.history['val_loss'])\n",
    "validation_ax.plot(history.history['val_acc'])\n",
    "validation_ax.set_title('Validation loss and accuracy')\n",
    "validation_ax.set_xlabel('epoch')\n",
    "validation_ax.legend(['val_loss', 'val_accuracy'], loc='upper right')\n",
    "\n",
    "tarin_val_loss_fig = plt.figure()\n",
    "tarin_val_loss_ax = tarin_val_loss_fig.add_subplot(111)\n",
    "tarin_val_loss_ax.plot(history.history['loss'])\n",
    "tarin_val_loss_ax.plot(history.history['val_loss'])\n",
    "tarin_val_loss_ax.set_title('Training and Validation loss')\n",
    "tarin_val_loss_ax.set_xlabel('epoch')\n",
    "tarin_val_loss_ax.legend(['loss', 'val_loss'], loc='upper right')\n",
    "\n",
    "tarin_val_loss_fig = plt.figure()\n",
    "tarin_val_loss_ax = tarin_val_loss_fig.add_subplot(111)\n",
    "tarin_val_loss_ax.plot(history.history['acc'])\n",
    "tarin_val_loss_ax.plot(history.history['val_acc'])\n",
    "tarin_val_loss_ax.set_title('Training and Validation accuracy')\n",
    "tarin_val_loss_ax.set_xlabel('epoch')\n",
    "tarin_val_loss_ax.legend(['accuracy', 'val_accuracy'], loc='upper right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output:\n",
    "<p>Your plots should be similar to the ones below, but they won't be exact match</P>\n",
    "<p><img src=\"Figure2.png\" width=\"40%\" height=\"40%\" align=\"left\"> <br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the model on the training and test images.  First, we will need to get the h values.  Keep in mind that the we need to inverse transform the 1hot encoded labels to the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train_1hot = model.predict(X_train_flat)\n",
    "h_train_1hot = np.array([elm for elm in p_train_1hot>0.5], dtype=int) #Convert probabilities to class labels)\n",
    "h_train =  np.squeeze(cat_encoder.inverse_transform(h_train_1hot)) #Retrive original class labels)\n",
    "\n",
    "p_train_1hot = model.predict(X_test_flat)\n",
    "h_test_1hot = np.array([elm for elm in p_train_1hot>0.5], dtype=int) \n",
    "h_test =  np.squeeze(cat_encoder.inverse_transform(h_test_1hot)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will measure the model performance on the training set and test set using Confusion Matrix, Average Accuracy, Average Precision, Average Recall and Average F1-Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revise your code from last assignment and place it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output:\n",
    "<p> You performance should be close to the following, it won't be exact.</p>\n",
    "<p><img src=\"Figure4.png\" width=\"40%\" height=\"40%\" align=\"left\"> <br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's examine a set of images and compare their predicted and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "#Place your code from last assignment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected output:\n",
    "<p> You output should be close to the following, but it won't be exact.</p>\n",
    "<p><img src=\"Figure5.png\" width=\"20%\" height=\"20%\" align=\"left\"> <br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
